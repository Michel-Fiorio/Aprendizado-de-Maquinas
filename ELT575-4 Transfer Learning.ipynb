{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOSEYY7TRMFFS9cMj4nacoP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Semana 4 - Michel B Fiorio"],"metadata":{"id":"zYtlQEHJJoXo"}},{"cell_type":"markdown","source":["### Parte 1:"],"metadata":{"id":"2Zl02_unJtc-"}},{"cell_type":"markdown","source":["1 - Com base no que vimos no curso, aponte em quais casos as redes neurais recorrentes (RNN) e redes neurais convolucionais (CNN) devem ser aplicadas. Quais características dessas redes favorecem cada tipo de aplicação?\n","\n","**Resposta**: \n","\n","As redes neurais convolucionais são redes neurais que utilizam da operação matemática da convolução em pelo menos uma de suas camadas. A inspiração para a criação das camadas convolucionais se dá na organização do córtex visual humano. Em se tratando da arquitetura da camada convolucional de uma CNN, cada neurônio dessa camada está conectado a um número limitado de entradas dos neurônios da camada subsequente. Devido a sua arquitetura as CNNs são especialmente utilizadas em tarefas complexas de classificação de imagens.\n","\n","Já nas redes neurais recorrentes, o seu diferencial está na implementação de loops de realimentação da informação de saída de neurônios. Esses loops criam a capacidade de memória nos nós da rede e com isso vem a capacidade de noção de ordem das informações no tempo. A rede se torna capaz de interpretar informações que tenham sequência temporal e por isso ela é aplicada em problema onde os dados de entrada tem alguma dependência temporal, como series temporais de ações da bolsa de valores, textos, arquivos de áudio da fala humana, etc."],"metadata":{"id":"wLlwwzu9VgcL"}},{"cell_type":"markdown","source":["2 - No que consiste a técnica Transfer Learning? Por que essa técnica é muito utilizada em problemas relacionados com imagens?\n","\n","**Resposta**:\n","\n","A técnica de Transfer Learning consiste na reutilização de modelos já treinados para criação de novos modelos que executarão tarefas similares. Essa técnica permite minimizar o tempo e custo computacional no treinamento de modelos profundos. O Transfer Learning é útil e frequentemente utilizado em modelos de classificação de imagens, principalmente em aplicações onde a quantidade de dados disponível para treinamento do modelo é limitada tornando impossível o treinamento de um modelo a partir do zero.\n","\n"],"metadata":{"id":"Ro9gcRAZJ8Em"}},{"cell_type":"markdown","source":["3 - O que são os autoencoders? Explique com suas palavras como esse tipo de modelo funciona.\n","\n","**Resposta**: \n","\n","Autoencoders são redes neurais que combinam a aplicação de duas redes feedforward para formar uma rede maior que ganha capacidades complexas que as diferenciam das demais, tais como a geração de dados novos e segmentação de imagens. A ideia se baseia no fato de que em uma rede neural normal as informações extraídas dos dados de entrada são armazenadas nas camadas e a cada camada a rede vai aumentando a complexidade da representação das características dos dados. Então, é acoplada uma outra rede à saída dessa primeira. Essa segunda rede ganha a função de \"desenrolar\" a representação dos dados feita na primeira rede para reconstruir o dado original. Portanto o autoencoder tem a característica de possuir o mesmo número de neurônios na entrada e na saída. A primeira rede chama-se encoder e a segunda rede é chamada decoder. A saída será uma representação esparsa dos dados de entrada.\n"],"metadata":{"id":"UHrXxPVHJ-_u"}},{"cell_type":"markdown","source":["4 - Procure algum exemplo de aplicação recente de técnicas de Aprendizado Profundo para a solução de algum problema que ache relevante (classificação/identificação de doenças em plantas, diagnóstico médico, anaĺise de textos em redes sociais, previsão de ações da bolsa de valores, etc.). Explique o exemplo encontrado, destacando a importância do problema, a estratégia usada para resolvê-lo e os resultados obtidos.\n","\n","**Resposta**: \n","\n","O estudo disponível no link abaixo se propôs a apresentar um comparativo dos resultados de uma rede neural convolucional comparada com outras duas técnicas tradicionais na aplicação de detecção de pedestres (pessoas em pé) em imagens. Motivados pela grande importância e utilidade desse problema para aplicações de segurança, robótica e carros autônomos, dentre outras, diversos trabalhos tem sido realizados com proposições de arquiteturas específicas para essa tarefa.\n","\n","Nesse estudo em particular foi realizado o comparativo dos resultados da CNN com as técnicas Features de Haar e Histograma de Gradientes Orientado (HOG). Entretanto, dado o interesse apenas nos resultados da CNN, excluiremos o comparativo entre as técnicas.\n","\n","A CNN com o melhor resultado na tarefa de detecção de pedrestes foi obtida através de um transfer learning da rede AlexNet. A base de dados de treinamento foi a Caltech, uma base de dados popular de detecção de pedrestes. A base de testes possuia 21084 exemplos de pedestres e 22384 imagens sem pedestres. As métricas obtidas dos resultados foram a sensitividade, especificidade, precisão e acurácia. Segue abaixo os resultados obtidos para a CNN:\n","\n","- Sensitividade: 98,94%\n","- Especificidade: 99,17%\n","- Precisão: 99,12%\n","- Acurácia: 95,98%\n","\n","Referência bibliográfica: http://gibis.unifesp.br/sibgrapi16/eproceedings/wuw/7.pdf"],"metadata":{"id":"9_thgb7-KBFP"}},{"cell_type":"markdown","source":["### Parte 2:"],"metadata":{"id":"ggUU0UlaJ1-u"}},{"cell_type":"markdown","source":["Aplique a técnica de transfer learning para treinar um novo modelo para classificar o dataset CIFAR-10, usado na Atividade 2. Comente sobre os resultados obtidos neste experimento quando comparados com os resultados obtidos na realização da Atividade 2. Foi mais fácil e rápido treinar o modelo usando transfer learning?\n","\n","\n","DICA: O script pode uma modificação do que foi usado na Atividade 2, alterando apenas a parte de construção do modelo para usar um modelo pré-treinado (recomenda-se o VGG16) seguido de camadas totalmente conectadas, como no exemplo Transfer_learning_CNN.ipynb, disponibilizado na plataforma.\n"],"metadata":{"id":"MIykTBKRJy4G"}},{"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input"],"metadata":{"id":"gC5XaYe3WV-3","executionInfo":{"status":"ok","timestamp":1678198130285,"user_tz":180,"elapsed":12104,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["#### Importanto dados"],"metadata":{"id":"gPmTvh1QXzfX"}},{"cell_type":"code","source":["# carregando dataset\n","\n","(treinamentoX, treinamentoY), (testeX, testeY) = cifar10.load_data()"],"metadata":{"id":"qx63IJKzWYi4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678198137486,"user_tz":180,"elapsed":7205,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"e9ea50f8-ca3a-4f6b-a1ff-04c9c36c32c3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 3s 0us/step\n"]}]},{"cell_type":"code","source":["treinamentoX.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yyAQL-2iWc-m","executionInfo":{"status":"ok","timestamp":1678198137486,"user_tz":180,"elapsed":14,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"e5a7b9a3-0a66-41a4-d9bf-0bbf1d5b601a"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Convertendo valores dos pixels em float\n","treinamentoX = treinamentoX.astype('float32')\n","testeX = testeX.astype('float32')\n","\n","# normalização para escala [0-1]\n","treinamentoX = treinamentoX / 255.0\n","testeX = testeX / 255.0\n","\n","# transformando a variável alvo (target) para uma codificação one hot\n","treinamentoY = to_categorical(treinamentoY)\n","testeY = to_categorical(testeY)"],"metadata":{"id":"-Ygd1MMWWk83","executionInfo":{"status":"ok","timestamp":1678198140159,"user_tz":180,"elapsed":2684,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["testeY[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePjc4kaPWl0d","executionInfo":{"status":"ok","timestamp":1678198140159,"user_tz":180,"elapsed":5,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"dcf63374-c76c-4aec-84e0-a8cbbcff3c1e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["#### Defininido modelo obtido no exercício da semana 2 (sem Transfer Learning)"],"metadata":{"id":"fJ3H5U3wYxfG"}},{"cell_type":"code","source":["# definindo modelo\n","def define_model():\n","  model = Sequential()\n","  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))  #O 'input_shape' só precisa ser fornecido na 1ª camada convolucional\n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(.2))\n","  model.add(Conv2D(64, (3, 3), activation='relu'))  \n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(.2))\n","  model.add(Conv2D(64, (3, 3), activation='relu'))  \n","  model.add(MaxPooling2D((2, 2)))\n","  model.add(Dropout(.2))\n","  model.add(Flatten())\n","  model.add(Dense(100, activation='relu'))\n","  model.add(Dense(10, activation='softmax'))\n","  \n","  # compilando modelo\n","  opt = Adam(learning_rate=0.001)\n","  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model"],"metadata":{"id":"TGV5dGb3dAbi","executionInfo":{"status":"ok","timestamp":1678198140160,"user_tz":180,"elapsed":4,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#### Treinando o modelo (sem Transfer Learning)"],"metadata":{"id":"4ggyeybpfTkK"}},{"cell_type":"code","source":["# criando o modelo\n","model = define_model()\n","  \n","# treinamento do modelo\n","history = model.fit(treinamentoX, treinamentoY, \n","                    epochs=10, batch_size=32, \n","                    validation_split=0.2, \n","                    verbose=1)\n","  \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vs_GMEYmfU8h","executionInfo":{"status":"ok","timestamp":1678198880735,"user_tz":180,"elapsed":740578,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"d6d8c4be-7fdc-4b9b-8e85-2f07eeb2768e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1250/1250 [==============================] - 76s 59ms/step - loss: 1.6990 - accuracy: 0.3719 - val_loss: 1.4011 - val_accuracy: 0.4998\n","Epoch 2/10\n","1250/1250 [==============================] - 75s 60ms/step - loss: 1.3466 - accuracy: 0.5168 - val_loss: 1.2160 - val_accuracy: 0.5750\n","Epoch 3/10\n","1250/1250 [==============================] - 79s 63ms/step - loss: 1.2211 - accuracy: 0.5659 - val_loss: 1.0947 - val_accuracy: 0.6161\n","Epoch 4/10\n","1250/1250 [==============================] - 73s 58ms/step - loss: 1.1388 - accuracy: 0.5985 - val_loss: 1.0301 - val_accuracy: 0.6432\n","Epoch 5/10\n","1250/1250 [==============================] - 72s 58ms/step - loss: 1.0817 - accuracy: 0.6209 - val_loss: 1.0663 - val_accuracy: 0.6353\n","Epoch 6/10\n","1250/1250 [==============================] - 73s 58ms/step - loss: 1.0390 - accuracy: 0.6347 - val_loss: 0.9234 - val_accuracy: 0.6813\n","Epoch 7/10\n","1250/1250 [==============================] - 75s 60ms/step - loss: 1.0051 - accuracy: 0.6432 - val_loss: 0.9262 - val_accuracy: 0.6771\n","Epoch 8/10\n","1250/1250 [==============================] - 72s 58ms/step - loss: 0.9804 - accuracy: 0.6540 - val_loss: 0.9040 - val_accuracy: 0.6845\n","Epoch 9/10\n","1250/1250 [==============================] - 72s 58ms/step - loss: 0.9486 - accuracy: 0.6629 - val_loss: 0.8773 - val_accuracy: 0.6969\n","Epoch 10/10\n","1250/1250 [==============================] - 72s 58ms/step - loss: 0.9273 - accuracy: 0.6718 - val_loss: 0.8905 - val_accuracy: 0.6876\n"]}]},{"cell_type":"code","source":["# desempenho do modelo para os dados de teste\n","_, acc = model.evaluate(testeX, testeY, verbose=0)\n","print('Desempenho do modelo para os dados de teste > %.3f' % (acc * 100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKI632iBpZ3A","executionInfo":{"status":"ok","timestamp":1678198886298,"user_tz":180,"elapsed":5566,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"fa4a765a-226b-4e47-ce46-5c4127987bbe"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Desempenho do modelo para os dados de teste > 68.330\n"]}]},{"cell_type":"markdown","source":["#### Defininido modelo a partir do Transfer Learning da VGG16"],"metadata":{"id":"CoRqd97vZRIk"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkvbOiJDVH-4","executionInfo":{"status":"ok","timestamp":1678198887818,"user_tz":180,"elapsed":1523,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"3ae849fc-546f-4968-80e9-6829a3a140f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 1s 0us/step\n"]}],"source":["# definindo modelo usando transfer learning\n","\n","# Carregamos o modelo VGG16 sem as últimas camadas totalmente conectadas\n","pre_model = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n","\n","# Aqui fazemos com que as camadas do modelo pré-treinado não sejam alteradas durante o treino\n","for layer in pre_model.layers:\n","  layer.trainable = False\n","\n","# Criando o modelo sequencial\n","def define_transfer_model():\n","  model = Sequential()\n","  model.add(pre_model)\n","  model.add(Dropout(.2))\n","  model.add(Flatten())\n","  model.add(Dense(100, activation='relu'))\n","  model.add(Dense(10, activation='softmax'))\n","  \n","  # compilando modelo\n","  opt = Adam(learning_rate=0.001)\n","  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model"]},{"cell_type":"markdown","source":["#### Treinando o modelo com Transfer Learning"],"metadata":{"id":"m8eSQo5cZgVi"}},{"cell_type":"code","source":["# criando o modelo\n","model = define_model()\n","  \n","# treinamento do modelo\n","history = model.fit(treinamentoX, treinamentoY, \n","                    epochs=10, batch_size=32, \n","                    validation_split=0.2, \n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGeFTGo6rMOI","executionInfo":{"status":"ok","timestamp":1678199638577,"user_tz":180,"elapsed":750762,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"957504a9-2f0f-4bf4-afbb-2b24d03bb9e0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1250/1250 [==============================] - 75s 58ms/step - loss: 1.7025 - accuracy: 0.3678 - val_loss: 1.4218 - val_accuracy: 0.4780\n","Epoch 2/10\n","1250/1250 [==============================] - 73s 58ms/step - loss: 1.3874 - accuracy: 0.4985 - val_loss: 1.2523 - val_accuracy: 0.5457\n","Epoch 3/10\n","1250/1250 [==============================] - 71s 57ms/step - loss: 1.2614 - accuracy: 0.5498 - val_loss: 1.1234 - val_accuracy: 0.6078\n","Epoch 4/10\n","1250/1250 [==============================] - 77s 62ms/step - loss: 1.1792 - accuracy: 0.5774 - val_loss: 1.0622 - val_accuracy: 0.6339\n","Epoch 5/10\n","1250/1250 [==============================] - 78s 62ms/step - loss: 1.1121 - accuracy: 0.6058 - val_loss: 1.0203 - val_accuracy: 0.6472\n","Epoch 6/10\n","1250/1250 [==============================] - 74s 59ms/step - loss: 1.0727 - accuracy: 0.6196 - val_loss: 1.0250 - val_accuracy: 0.6407\n","Epoch 7/10\n","1250/1250 [==============================] - 72s 58ms/step - loss: 1.0328 - accuracy: 0.6354 - val_loss: 0.9651 - val_accuracy: 0.6595\n","Epoch 8/10\n","1250/1250 [==============================] - 78s 62ms/step - loss: 1.0019 - accuracy: 0.6452 - val_loss: 0.9224 - val_accuracy: 0.6826\n","Epoch 9/10\n","1250/1250 [==============================] - 78s 62ms/step - loss: 0.9733 - accuracy: 0.6547 - val_loss: 0.8920 - val_accuracy: 0.6871\n","Epoch 10/10\n","1250/1250 [==============================] - 73s 59ms/step - loss: 0.9514 - accuracy: 0.6652 - val_loss: 0.9144 - val_accuracy: 0.6781\n"]}]},{"cell_type":"code","source":["# desempenho do modelo para os dados de teste\n","_, acc = model.evaluate(testeX, testeY, verbose=0)\n","print('Desempenho do modelo para os dados de teste > %.3f' % (acc * 100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wsmn1TR9uG0J","executionInfo":{"status":"ok","timestamp":1678199644102,"user_tz":180,"elapsed":5530,"user":{"displayName":"Michel Batistin Fiorio","userId":"11739894702375358878"}},"outputId":"934067c6-520d-4079-f3c2-3bfe7a228558"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Desempenho do modelo para os dados de teste > 67.210\n"]}]},{"cell_type":"markdown","source":["**Comentário dos resultados**:\n","\n","- Tempo de treinamento do modelo da semana 2 (sem k-fold): 12 min\n","- Tempo de treinamento do modelo com Transfer Learning: 12 min\n","\n","- Desempenho do modelo da semana 2: 68,33%\n","- Desempenho do modelo com Transfer Learning: 67,21%\n","\n","Conforme podemos observamor nos resultados obtidos, não houve melhora significa do tempo de treinamento e no desempenho do modelo ao se aplicar a técnica de transfer learning nesse caso específico."],"metadata":{"id":"p1YcKIaBZpCw"}}]}